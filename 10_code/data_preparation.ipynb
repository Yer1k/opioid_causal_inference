{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Notebook\n",
    "\n",
    "#### This notebook will be the test bed for data read functions to ingest data from a data folder on the local machine\n",
    "\n",
    "#### The end outputs of this notebook are that all data structures will have a 'COUNTY NAME, ST' column, and where applicable a FIPS code as well. Merges will be performed elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# set the states concerned for the analysis\n",
    "states = [\n",
    "    \"FL\",\n",
    "    \"AL\",\n",
    "    \"GA\",\n",
    "    \"MS\",\n",
    "    \"SC\",\n",
    "    \"TX\",\n",
    "    \"OK\",\n",
    "    \"AZ\",\n",
    "    \"NM\",\n",
    "    \"WA\",\n",
    "    \"OR\",\n",
    "    \"ID\",\n",
    "    \"CA\",\n",
    "    \"NY\",\n",
    "]\n",
    "\n",
    "# Drop LA and NV because of issues. Carson city is an independent city in Nevada...??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingest the state abbreviations as its own DF\n",
    "state_df = pd.read_table(\"../00_source_data/03_state_names.rtf\", sep=\",\")\n",
    "state_df.columns = [\"STATE\", \"ABBREV\"]\n",
    "\n",
    "# make state upper\n",
    "state_df[\"STATE\"] = state_df[\"STATE\"].str.upper()\n",
    "\n",
    "# drop the trailing slash from the abbrev\n",
    "state_df[\"ABBREV\"] = state_df[\"ABBREV\"].str[0:2]\n",
    "# state_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WAPO Dataset\n",
    "\n",
    "This section takes an argument for the path to the WAPO dataset and will ultimately return an annualized dataframe of the states with respective values for each year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ingest actions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to WAPO file\n",
    "wapo = \"../00_source_data/prescription_data.zip\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest the WAPO file as chunks - takes roughly 15 minutes\n",
    "\n",
    "chunks = 500000  # Leave this, there will be 465 chunks\n",
    "\n",
    "chunk_counter = 0\n",
    "\n",
    "wapo_df = pd.DataFrame()\n",
    "\n",
    "for chunk in pd.read_csv(\n",
    "    wapo,\n",
    "    compression=\"zip\",\n",
    "    chunksize=chunks,\n",
    "    usecols=[\n",
    "        \"BUYER_COUNTY\",\n",
    "        \"BUYER_STATE\",\n",
    "        \"DRUG_NAME\",\n",
    "        \"TRANSACTION_DATE\",\n",
    "        \"QUANTITY\",\n",
    "        \"UNIT\",\n",
    "    ],\n",
    "):\n",
    "    chunk_counter += 1\n",
    "    percent_chunk = round(chunk_counter / 465 * 100, 2)\n",
    "    print(\"Reading chunk: \", chunk_counter, \"of 465 (\", percent_chunk, \"%)\")\n",
    "\n",
    "    # filter the chunk to only include the stations in the list\n",
    "    chunk = chunk[chunk[\"BUYER_STATE\"].isin(states)].copy()\n",
    "\n",
    "    chunk[\"TRANSACTION_DATE\"] = pd.to_datetime(\n",
    "        chunk[\"TRANSACTION_DATE\"], format=\"%m%d%Y\"\n",
    "    )\n",
    "\n",
    "    chunk[\"YEAR\"] = chunk[\"TRANSACTION_DATE\"].dt.year\n",
    "    chunk[\"MONTH\"] = chunk[\"TRANSACTION_DATE\"].dt.month\n",
    "\n",
    "    # make the quantity numeric\n",
    "    chunk[\"QUANTITY\"] = pd.to_numeric(chunk[\"QUANTITY\"], errors=\"coerce\")\n",
    "\n",
    "    chunk = chunk.groupby([\"BUYER_COUNTY\", \"BUYER_STATE\", \"YEAR\", \"MONTH\"]).agg(\n",
    "        {\"QUANTITY\": \"sum\"}\n",
    "    )\n",
    "\n",
    "    # concat with the base df\n",
    "    wapo_df = pd.concat([wapo_df, chunk])\n",
    "\n",
    "print(\"Ingest complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding county name...\n",
      "Grouping WAPO data...\n",
      "Operation complete\n"
     ]
    }
   ],
   "source": [
    "# transform the wapo df\n",
    "print(\"Adding county name...\")\n",
    "\n",
    "# Add an index to the wapo_df\n",
    "wapo_df = wapo_df.reset_index()\n",
    "\n",
    "# Do some transformations on the WAPO dataset\n",
    "wapo_df[\"COUNTY_NAME\"] = wapo_df[\"BUYER_COUNTY\"] + \" COUNTY, \" + wapo_df[\"BUYER_STATE\"]\n",
    "\n",
    "print(\"Grouping WAPO data...\")\n",
    "\n",
    "wapo_df = (\n",
    "    wapo_df.groupby([\"COUNTY_NAME\", \"BUYER_STATE\", \"YEAR\", \"MONTH\"])\n",
    "    .agg({\"QUANTITY\": \"sum\"})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# # rename buyer state to state\n",
    "wapo_df = wapo_df.rename(columns={\"BUYER_STATE\": \"STATE\"})\n",
    "\n",
    "# # Change the year column to a string\n",
    "wapo_df[\"YEAR\"] = wapo_df[\"YEAR\"].astype(str)\n",
    "\n",
    "# # Change the month column to a string\n",
    "wapo_df[\"MONTH\"] = wapo_df[\"MONTH\"].astype(str)\n",
    "\n",
    "print(\"Operation complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Print a sample to make sure you did it right***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wapo_df.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wapo_df[\"YEAR\"].unique()\n",
    "# wapo_df[\"STATE\"].unique()\n",
    "\n",
    "assert len(wapo_df[\"STATE\"].unique()) == len(states)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Assert tests to verify that we have the right states, and some checks on the data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert that no counties are missing\n",
    "assert wapo_df[\"COUNTY_NAME\"].isnull().sum() == 0\n",
    "# Assert that states are in the list\n",
    "assert set(wapo_df[\"STATE\"].unique()) == set(states)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Save the output file to a csv in the intermediate files directory***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this file as a csv called wapo_clean.csv in the current directory\n",
    "wapo_df.to_csv(\"../20_intermediate_files/wapo_clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vitality Data\n",
    "\n",
    "This section takes the txt files passed and will return a dataframe with the respective values for each year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ingest actions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a directory path to find the txt files\n",
    "nick_path = \"../00_source_data/US_VitalStatistics/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting text files...\n",
      "Transforming vitality data...\n",
      "Operation complete\n"
     ]
    }
   ],
   "source": [
    "# generate a df from the txt files in a folder path\n",
    "\n",
    "# initialize the empty df\n",
    "nick_df = pd.DataFrame()\n",
    "\n",
    "# set a loop to iterate through the files in the folder\n",
    "print(\"Ingesting text files...\")\n",
    "\n",
    "# set a loop to iterate through the files in the folder\n",
    "for file in os.listdir(nick_path):\n",
    "    if file.endswith(\".txt\"):\n",
    "        txt_table = pd.read_table(\n",
    "            os.path.join(nick_path, file), sep=\"\\t\", skipfooter=15, engine=\"python\"\n",
    "        )\n",
    "        # remove the bottom rows that are not needed\n",
    "        # txt_table = txt_table.iloc[0:-16, :]\n",
    "        nick_df = pd.concat([nick_df, txt_table], axis=0)\n",
    "\n",
    "# subset to the columns we want\n",
    "vital_df = nick_df[\n",
    "    [\n",
    "        \"County\",\n",
    "        \"County Code\",\n",
    "        \"Year\",\n",
    "        \"Drug/Alcohol Induced Cause\",\n",
    "        \"Drug/Alcohol Induced Cause Code\",\n",
    "        \"Deaths\",\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "print(\"Transforming vitality data...\")\n",
    "\n",
    "# change the year column to a string with a year only\n",
    "vital_df[\"Year\"] = vital_df[\"Year\"].astype(str).str[0:4]\n",
    "\n",
    "# change the County Code column to 6-digit string FIPS code\n",
    "vital_df[\"County Code\"] = vital_df[\"County Code\"].astype(str).str.zfill(6)\n",
    "\n",
    "# add a state column with the last two characters from county\n",
    "vital_df[\"State\"] = vital_df[\"County\"].str[-2:]\n",
    "\n",
    "# convert NaN deaths to 0\n",
    "vital_df[\"Deaths\"] = vital_df[\"Deaths\"].fillna(0)\n",
    "\n",
    "# change the county name to all caps\n",
    "vital_df[\"County\"] = vital_df[\"County\"].str.upper()\n",
    "\n",
    "# change all the column names to all caps\n",
    "vital_df.columns = vital_df.columns.str.upper()\n",
    "\n",
    "# rename county code to FIPS code\n",
    "vital_df = vital_df.rename(columns={\"COUNTY CODE\": \"FIPS\"})\n",
    "vital_df = vital_df.rename(columns={\"COUNTY\": \"COUNTY_NAME\"})\n",
    "\n",
    "# filter the vital df to the states of interest\n",
    "vital_df = vital_df[vital_df[\"STATE\"].isin(states)].copy()\n",
    "\n",
    "print(\"Operation complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Subset to rows with drug deaths, group and add***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vital_df[\"DRUG/ALCOHOL INDUCED CAUSE\"].value_counts()\n",
    "\n",
    "# convert the DRUG Cause column to all lower case\n",
    "vital_df[\"DRUG/ALCOHOL INDUCED CAUSE\"] = vital_df[\n",
    "    \"DRUG/ALCOHOL INDUCED CAUSE\"\n",
    "].str.lower()\n",
    "\n",
    "# Make a new column called drug with indicators for cause\n",
    "vital_df[\"DRUG\"] = np.where(\n",
    "    vital_df[\"DRUG/ALCOHOL INDUCED CAUSE\"].str.contains(\"drug\"), 1, 0\n",
    ")\n",
    "\n",
    "# subset to remove all other non-drug deaths\n",
    "vital_df = vital_df[\n",
    "    vital_df[\"DRUG/ALCOHOL INDUCED CAUSE\"]\n",
    "    != \"all other non-drug and non-alcohol causes\"\n",
    "].copy()\n",
    "\n",
    "# subset to remove all other non-drug deaths\n",
    "vital_df = vital_df[vital_df[\"DRUG\"] == 1].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drug poisonings (overdose) unintentional (x40-x44)    3017\n",
       "drug poisonings (overdose) suicide (x60-x64)           783\n",
       "all other drug-induced causes                          326\n",
       "drug poisonings (overdose) undetermined (y10-y14)      195\n",
       "Name: DRUG/ALCOHOL INDUCED CAUSE, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vital_df[\"DRUG/ALCOHOL INDUCED CAUSE\"].unique()\n",
    "vital_df[\"DRUG/ALCOHOL INDUCED CAUSE\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the death column to an integer\n",
    "vital_df[\"DEATHS\"] = vital_df[\"DEATHS\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rp/l0l3mhgx4zs1vfg5y9_c2qw80000gn/T/ipykernel_87825/2321280978.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  .sum()\n"
     ]
    }
   ],
   "source": [
    "# group the vital df and sum the deaths\n",
    "new_vital_df = (\n",
    "    vital_df.groupby([\"COUNTY_NAME\", \"FIPS\", \"YEAR\", \"STATE\", \"DRUG\"])\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Check a sample to inspect data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_vital_df.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Assert tests to verify that we have the right states, and some checks on the data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert vital_df.all().isnull().sum() == 0\n",
    "# Assert that states are in the list\n",
    "assert set(vital_df[\"STATE\"].unique()) == set(states)\n",
    "# Still need to find a way to check if Vital is correctly chunked\n",
    "\n",
    "assert vital_df[\"DEATHS\"].sum() == new_vital_df[\"DEATHS\"].sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Save the output dataframe to the intermediate files directory***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vital_df.to_csv(\"../20_intermediate_files/vital_clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add FIPS Codes to the available data\n",
    "\n",
    "This chunk takes the path to FIPS codes and will ingest them into a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ingest data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_path = \"../00_source_data/02_fcc_fips_codes.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***start with counties***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation complete\n"
     ]
    }
   ],
   "source": [
    "# Ingest the fips codes\n",
    "fips_county_df = pd.read_table(fips_path, sep=\"\\t\", skiprows=71, header=\"infer\")\n",
    "\n",
    "# name the column header\n",
    "fips_county_df.columns = [\"FIPS\"]\n",
    "\n",
    "# split the FIPS column into two columns after the first 5 characters\n",
    "fips_county_df[\"COUNTY_NAME\"] = fips_county_df[\"FIPS\"].str[10:]\n",
    "\n",
    "# Turn the FIPS column into just the numbers\n",
    "fips_county_df[\"FIPS\"] = fips_county_df[\"FIPS\"].str[4:10]\n",
    "\n",
    "# remove the spaces from the county name\n",
    "fips_county_df[\"COUNTY_NAME\"] = fips_county_df[\"COUNTY_NAME\"].str.strip()\n",
    "\n",
    "# make county name upper\n",
    "fips_county_df[\"COUNTY_NAME\"] = fips_county_df[\"COUNTY_NAME\"].str.upper()\n",
    "\n",
    "print(\"Operation complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation complete\n"
     ]
    }
   ],
   "source": [
    "# Ingest the fips codes\n",
    "fips_state_df = pd.read_table(fips_path, sep=\"\\t\", skiprows=15, header=\"infer\")\n",
    "\n",
    "# keep the first 50 rows\n",
    "fips_state_df = fips_state_df.iloc[0:50, :]\n",
    "\n",
    "# name the column header\n",
    "fips_state_df.columns = [\"FIPS\"]\n",
    "\n",
    "# # split the FIPS column into two columns after the first 5 characters\n",
    "fips_state_df[\"STATE\"] = fips_state_df[\"FIPS\"].str[10:]\n",
    "fips_state_df[\"STATE\"] = fips_state_df[\"STATE\"].str.strip()\n",
    "\n",
    "# #Turn the FIPS column into just the numbers\n",
    "fips_state_df[\"FIPS\"] = fips_state_df[\"FIPS\"].str[4:10]\n",
    "\n",
    "# merge to add the state abbreviations from the state_df\n",
    "fips_state_df = fips_state_df.merge(state_df, on=\"STATE\", how=\"left\")\n",
    "\n",
    "print(\"Operation complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***merge the two dataframes***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is going to be a little different\n",
    "fips_df = fips_county_df.copy()\n",
    "\n",
    "# add a state column\n",
    "fips_df[\"STATE\"] = fips_df[\"COUNTY_NAME\"]\n",
    "\n",
    "# merge to get the state abbreviations\n",
    "fips_df = fips_df.merge(fips_state_df, on=\"STATE\", how=\"left\")\n",
    "\n",
    "# drop the state column\n",
    "fips_df = fips_df.drop(columns=[\"STATE\"])\n",
    "\n",
    "# rename the columns\n",
    "fips_df = fips_df.rename(\n",
    "    columns={\"FIPS_x\": \"FIPS\", \"ABBREV\": \"STATE\", \"FIPS_y\": \"STATE_FIPS\"}\n",
    ")\n",
    "\n",
    "# forward fill the state fips and state columns\n",
    "fips_df[\"STATE_FIPS\"] = fips_df[\"STATE_FIPS\"].fillna(method=\"ffill\")\n",
    "fips_df[\"STATE\"] = fips_df[\"STATE\"].fillna(method=\"ffill\")\n",
    "\n",
    "# add state to the county name\n",
    "fips_df[\"COUNTY_NAME\"] = fips_df[\"COUNTY_NAME\"] + \", \" + fips_df[\"STATE\"]\n",
    "\n",
    "# filter the df to the states of interest\n",
    "fips_df = fips_df[fips_df[\"STATE\"].isin(states)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Sample the FIPS codes to see if we did it right***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fips_df.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Add some assert tests***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert vital_df.all().isnull().sum() == 0\n",
    "# check the first two digits of the FIPS code to make sure they match with STATE_FIPS\n",
    "assert list(fips_df[\"FIPS\"].str[:2]) == list(\n",
    "    fips_df[\"STATE_FIPS\"].astype(str).str.strip()\n",
    ")\n",
    "# fips_df[\"FIPS\"].dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Save the FIPS file cleaned to the 20_intermediate_files directory***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fips_df to a csv\n",
    "fips_df.to_csv(\"../20_intermediate_files/fips_df.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census Data\n",
    "\n",
    "This chunk will ingest filtered county population data and return a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ingest data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the directory path to the raw data\n",
    "census_path = \"../00_source_data/01_census_data.xlsx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingest the raw data and filter for states of interest\n",
    "census_df = pd.read_excel(census_path, header=0, skiprows=4, usecols=\"A:B\")\n",
    "\n",
    "# Change the column names to county name and population\n",
    "census_df.columns = [\"COUNTY_NAME\", \"POPULATION\"]\n",
    "\n",
    "# remove the leading period from the county name\n",
    "census_df[\"COUNTY_NAME\"] = census_df[\"COUNTY_NAME\"].str[1:]\n",
    "\n",
    "# move the state name to its own column\n",
    "census_df[\"STATE\"] = census_df[\"COUNTY_NAME\"].str.split(\",\").str[1]\n",
    "census_df[\"STATE\"] = census_df[\"STATE\"].str.strip()\n",
    "census_df[\"STATE\"] = census_df[\"STATE\"].str.upper()\n",
    "\n",
    "# remove the state name from the county name\n",
    "census_df[\"COUNTY_NAME\"] = census_df[\"COUNTY_NAME\"].str.split(\",\").str[0]\n",
    "\n",
    "# change population to an integer\n",
    "census_df[\"POPULATION\"] = census_df[\"POPULATION\"].astype(\"Int64\")\n",
    "\n",
    "# add an abbreviation column for the state from the state_df\n",
    "census_df_merge = census_df.merge(state_df, on=\"STATE\", how=\"outer\")\n",
    "\n",
    "# reformat county name to include abbrev\n",
    "census_df_merge[\"COUNTY_NAME\"] = (\n",
    "    census_df_merge[\"COUNTY_NAME\"] + \", \" + census_df_merge[\"ABBREV\"]\n",
    ")\n",
    "census_df_merge[\"COUNTY_NAME\"] = census_df_merge[\"COUNTY_NAME\"].str.upper()\n",
    "\n",
    "# remove the state column\n",
    "census_df_merge = census_df_merge.drop(columns=\"STATE\")\n",
    "\n",
    "# rename the abbrev column to state\n",
    "census_df_merge = census_df_merge.rename(columns={\"ABBREV\": \"STATE\"})\n",
    "\n",
    "# filter for the states of interest\n",
    "census_df_merge = census_df_merge[census_df_merge[\"STATE\"].isin(states)].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Sample to see if we did it right***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AL', 'AZ', 'CA', 'FL', 'GA', 'ID', 'MS', 'NM', 'NY', 'OK', 'OR',\n",
       "       'SC', 'TX', 'WA'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_df_merge[\"STATE\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# census_df_merge.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Add assert tests***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of counties in each state we have picked, according to google and wikipedia\n",
    "counties = {\"FL\":67,\"AL\":67, \"GA\":159, \"MS\":82, \"SC\":46, \"TX\":254 , \"OK\":77, \"AZ\":15, \"NM\":33, \"WA\":39, \"OR\":36, \"ID\":44, \"CA\":58, \"NY\":62}\n",
    "# check we have all the counties in our dictionary\n",
    "assert set(census_df_merge[\"STATE\"].unique()) == set(counties.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert census_df_merge.all().isnull().sum() == 0\n",
    "# check last two characters of county name to make sure they match with state\n",
    "assert list(census_df_merge[\"COUNTY_NAME\"].str[-2:]) == list(census_df_merge[\"STATE\"])\n",
    "# we need to check county numbers to make sure they match (when we know which control states we want)\n",
    "assert census_df_merge[\"COUNTY_NAME\"].nunique() == sum(counties.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Save the output file to the intermediate files directory***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the file to the intermediate folder\n",
    "census_df_merge.to_csv(\"../20_intermediate_files/census_df.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"DEBACA COUNTY, NM\" in census_df_merge[\"COUNTY_NAME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"DONA ANA COUNTY, NM\" in census_df_merge[\"COUNTY_NAME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(census_df_merge[census_df_merge[\"STATE\"]==\"NM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTY_NAME</th>\n",
       "      <th>POPULATION</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>BERNALILLO COUNTY, NM</td>\n",
       "      <td>662564</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>CATRON COUNTY, NM</td>\n",
       "      <td>3725</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>CHAVES COUNTY, NM</td>\n",
       "      <td>65645</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>CIBOLA COUNTY, NM</td>\n",
       "      <td>27213</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>COLFAX COUNTY, NM</td>\n",
       "      <td>13750</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>CURRY COUNTY, NM</td>\n",
       "      <td>48376</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>DE BACA COUNTY, NM</td>\n",
       "      <td>2022</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>DOÑA ANA COUNTY, NM</td>\n",
       "      <td>209233</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>EDDY COUNTY, NM</td>\n",
       "      <td>53829</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>GRANT COUNTY, NM</td>\n",
       "      <td>29514</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>GUADALUPE COUNTY, NM</td>\n",
       "      <td>4687</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>HARDING COUNTY, NM</td>\n",
       "      <td>695</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>HIDALGO COUNTY, NM</td>\n",
       "      <td>4894</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>LEA COUNTY, NM</td>\n",
       "      <td>64727</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>LINCOLN COUNTY, NM</td>\n",
       "      <td>20497</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>LOS ALAMOS COUNTY, NM</td>\n",
       "      <td>17950</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>LUNA COUNTY, NM</td>\n",
       "      <td>25095</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>MCKINLEY COUNTY, NM</td>\n",
       "      <td>71492</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>MORA COUNTY, NM</td>\n",
       "      <td>4881</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>OTERO COUNTY, NM</td>\n",
       "      <td>63797</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>QUAY COUNTY, NM</td>\n",
       "      <td>9041</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>RIO ARRIBA COUNTY, NM</td>\n",
       "      <td>40246</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>ROOSEVELT COUNTY, NM</td>\n",
       "      <td>19846</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>SANDOVAL COUNTY, NM</td>\n",
       "      <td>131561</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>SAN JUAN COUNTY, NM</td>\n",
       "      <td>130044</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>SAN MIGUEL COUNTY, NM</td>\n",
       "      <td>29393</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>SANTA FE COUNTY, NM</td>\n",
       "      <td>144170</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>SIERRA COUNTY, NM</td>\n",
       "      <td>11988</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>SOCORRO COUNTY, NM</td>\n",
       "      <td>17866</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>TAOS COUNTY, NM</td>\n",
       "      <td>32937</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>TORRANCE COUNTY, NM</td>\n",
       "      <td>16383</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>UNION COUNTY, NM</td>\n",
       "      <td>4549</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>VALENCIA COUNTY, NM</td>\n",
       "      <td>76569</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                COUNTY_NAME  POPULATION STATE\n",
       "1795  BERNALILLO COUNTY, NM      662564    NM\n",
       "1796      CATRON COUNTY, NM        3725    NM\n",
       "1797      CHAVES COUNTY, NM       65645    NM\n",
       "1798      CIBOLA COUNTY, NM       27213    NM\n",
       "1799      COLFAX COUNTY, NM       13750    NM\n",
       "1800       CURRY COUNTY, NM       48376    NM\n",
       "1801     DE BACA COUNTY, NM        2022    NM\n",
       "1802    DOÑA ANA COUNTY, NM      209233    NM\n",
       "1803        EDDY COUNTY, NM       53829    NM\n",
       "1804       GRANT COUNTY, NM       29514    NM\n",
       "1805   GUADALUPE COUNTY, NM        4687    NM\n",
       "1806     HARDING COUNTY, NM         695    NM\n",
       "1807     HIDALGO COUNTY, NM        4894    NM\n",
       "1808         LEA COUNTY, NM       64727    NM\n",
       "1809     LINCOLN COUNTY, NM       20497    NM\n",
       "1810  LOS ALAMOS COUNTY, NM       17950    NM\n",
       "1811        LUNA COUNTY, NM       25095    NM\n",
       "1812    MCKINLEY COUNTY, NM       71492    NM\n",
       "1813        MORA COUNTY, NM        4881    NM\n",
       "1814       OTERO COUNTY, NM       63797    NM\n",
       "1815        QUAY COUNTY, NM        9041    NM\n",
       "1816  RIO ARRIBA COUNTY, NM       40246    NM\n",
       "1817   ROOSEVELT COUNTY, NM       19846    NM\n",
       "1818    SANDOVAL COUNTY, NM      131561    NM\n",
       "1819    SAN JUAN COUNTY, NM      130044    NM\n",
       "1820  SAN MIGUEL COUNTY, NM       29393    NM\n",
       "1821    SANTA FE COUNTY, NM      144170    NM\n",
       "1822      SIERRA COUNTY, NM       11988    NM\n",
       "1823     SOCORRO COUNTY, NM       17866    NM\n",
       "1824        TAOS COUNTY, NM       32937    NM\n",
       "1825    TORRANCE COUNTY, NM       16383    NM\n",
       "1826       UNION COUNTY, NM        4549    NM\n",
       "1827    VALENCIA COUNTY, NM       76569    NM"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_df_merge[census_df_merge[\"STATE\"]==\"NM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84b9370629bc80826ce6aeb009e770dfe4ed6af6eef03d00ae361c57df430492"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

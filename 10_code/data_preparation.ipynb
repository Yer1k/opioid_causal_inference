{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Notebook\n",
    "\n",
    "#### This notebook will be the test bed for data read functions to ingest data from a data folder on the local machine\n",
    "\n",
    "#### The end outputs of this notebook are that all data structures will have a 'COUNTY NAME, ST' column, and where applicable a FIPS code as well. Merges will be performed elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# set the states concerned for the analysis\n",
    "states = [\"FL\", \"TX\", \"WA\", \"OR\", \"AL\", \"OK\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>ABBREV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALASKA</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        STATE ABBREV\n",
       "0     ALABAMA     AL\n",
       "1      ALASKA     AK\n",
       "2     ARIZONA     AZ\n",
       "3    ARKANSAS     AR\n",
       "4  CALIFORNIA     CA"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ingest the state abbreviations as its own DF\n",
    "state_df = pd.read_table(\"../00_source_data/03_state_names.rtf\", sep=\",\")\n",
    "state_df.columns = [\"STATE\", \"ABBREV\"]\n",
    "\n",
    "# make state upper\n",
    "state_df[\"STATE\"] = state_df[\"STATE\"].str.upper()\n",
    "\n",
    "# drop the trailing slash from the abbrev\n",
    "state_df[\"ABBREV\"] = state_df[\"ABBREV\"].str[0:2]\n",
    "# state_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WAPO Dataset\n",
    "\n",
    "This section takes an argument for the path to the WAPO dataset and will ultimately return an annualized dataframe of the states with respective values for each year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ingest actions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to WAPO file\n",
    "wapo = \"/Users/andrewkroening/Desktop/720_Data/arcos_all_washpost.tsv.gz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  1 of 358 ( 0.28 %)\n",
      "Reading chunk:  2 of 358 ( 0.56 %)\n",
      "Reading chunk:  3 of 358 ( 0.84 %)\n",
      "Reading chunk:  4 of 358 ( 1.12 %)\n",
      "Reading chunk:  5 of 358 ( 1.4 %)\n",
      "Reading chunk:  6 of 358 ( 1.68 %)\n",
      "Reading chunk:  7 of 358 ( 1.96 %)\n",
      "Reading chunk:  8 of 358 ( 2.23 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  9 of 358 ( 2.51 %)\n",
      "Reading chunk:  10 of 358 ( 2.79 %)\n",
      "Reading chunk:  11 of 358 ( 3.07 %)\n",
      "Reading chunk:  12 of 358 ( 3.35 %)\n",
      "Reading chunk:  13 of 358 ( 3.63 %)\n",
      "Reading chunk:  14 of 358 ( 3.91 %)\n",
      "Reading chunk:  15 of 358 ( 4.19 %)\n",
      "Reading chunk:  16 of 358 ( 4.47 %)\n",
      "Reading chunk:  17 of 358 ( 4.75 %)\n",
      "Reading chunk:  18 of 358 ( 5.03 %)\n",
      "Reading chunk:  19 of 358 ( 5.31 %)\n",
      "Reading chunk:  20 of 358 ( 5.59 %)\n",
      "Reading chunk:  21 of 358 ( 5.87 %)\n",
      "Reading chunk:  22 of 358 ( 6.15 %)\n",
      "Reading chunk:  23 of 358 ( 6.42 %)\n",
      "Reading chunk:  24 of 358 ( 6.7 %)\n",
      "Reading chunk:  25 of 358 ( 6.98 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  26 of 358 ( 7.26 %)\n",
      "Reading chunk:  27 of 358 ( 7.54 %)\n",
      "Reading chunk:  28 of 358 ( 7.82 %)\n",
      "Reading chunk:  29 of 358 ( 8.1 %)\n",
      "Reading chunk:  30 of 358 ( 8.38 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  31 of 358 ( 8.66 %)\n",
      "Reading chunk:  32 of 358 ( 8.94 %)\n",
      "Reading chunk:  33 of 358 ( 9.22 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  34 of 358 ( 9.5 %)\n",
      "Reading chunk:  35 of 358 ( 9.78 %)\n",
      "Reading chunk:  36 of 358 ( 10.06 %)\n",
      "Reading chunk:  37 of 358 ( 10.34 %)\n",
      "Reading chunk:  38 of 358 ( 10.61 %)\n",
      "Reading chunk:  39 of 358 ( 10.89 %)\n",
      "Reading chunk:  40 of 358 ( 11.17 %)\n",
      "Reading chunk:  41 of 358 ( 11.45 %)\n",
      "Reading chunk:  42 of 358 ( 11.73 %)\n",
      "Reading chunk:  43 of 358 ( 12.01 %)\n",
      "Reading chunk:  44 of 358 ( 12.29 %)\n",
      "Reading chunk:  45 of 358 ( 12.57 %)\n",
      "Reading chunk:  46 of 358 ( 12.85 %)\n",
      "Reading chunk:  47 of 358 ( 13.13 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  48 of 358 ( 13.41 %)\n",
      "Reading chunk:  49 of 358 ( 13.69 %)\n",
      "Reading chunk:  50 of 358 ( 13.97 %)\n",
      "Reading chunk:  51 of 358 ( 14.25 %)\n",
      "Reading chunk:  52 of 358 ( 14.53 %)\n",
      "Reading chunk:  53 of 358 ( 14.8 %)\n",
      "Reading chunk:  54 of 358 ( 15.08 %)\n",
      "Reading chunk:  55 of 358 ( 15.36 %)\n",
      "Reading chunk:  56 of 358 ( 15.64 %)\n",
      "Reading chunk:  57 of 358 ( 15.92 %)\n",
      "Reading chunk:  58 of 358 ( 16.2 %)\n",
      "Reading chunk:  59 of 358 ( 16.48 %)\n",
      "Reading chunk:  60 of 358 ( 16.76 %)\n",
      "Reading chunk:  61 of 358 ( 17.04 %)\n",
      "Reading chunk:  62 of 358 ( 17.32 %)\n",
      "Reading chunk:  63 of 358 ( 17.6 %)\n",
      "Reading chunk:  64 of 358 ( 17.88 %)\n",
      "Reading chunk:  65 of 358 ( 18.16 %)\n",
      "Reading chunk:  66 of 358 ( 18.44 %)\n",
      "Reading chunk:  67 of 358 ( 18.72 %)\n",
      "Reading chunk:  68 of 358 ( 18.99 %)\n",
      "Reading chunk:  69 of 358 ( 19.27 %)\n",
      "Reading chunk:  70 of 358 ( 19.55 %)\n",
      "Reading chunk:  71 of 358 ( 19.83 %)\n",
      "Reading chunk:  72 of 358 ( 20.11 %)\n",
      "Reading chunk:  73 of 358 ( 20.39 %)\n",
      "Reading chunk:  74 of 358 ( 20.67 %)\n",
      "Reading chunk:  75 of 358 ( 20.95 %)\n",
      "Reading chunk:  76 of 358 ( 21.23 %)\n",
      "Reading chunk:  77 of 358 ( 21.51 %)\n",
      "Reading chunk:  78 of 358 ( 21.79 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  79 of 358 ( 22.07 %)\n",
      "Reading chunk:  80 of 358 ( 22.35 %)\n",
      "Reading chunk:  81 of 358 ( 22.63 %)\n",
      "Reading chunk:  82 of 358 ( 22.91 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  83 of 358 ( 23.18 %)\n",
      "Reading chunk:  84 of 358 ( 23.46 %)\n",
      "Reading chunk:  85 of 358 ( 23.74 %)\n",
      "Reading chunk:  86 of 358 ( 24.02 %)\n",
      "Reading chunk:  87 of 358 ( 24.3 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  88 of 358 ( 24.58 %)\n",
      "Reading chunk:  89 of 358 ( 24.86 %)\n",
      "Reading chunk:  90 of 358 ( 25.14 %)\n",
      "Reading chunk:  91 of 358 ( 25.42 %)\n",
      "Reading chunk:  92 of 358 ( 25.7 %)\n",
      "Reading chunk:  93 of 358 ( 25.98 %)\n",
      "Reading chunk:  94 of 358 ( 26.26 %)\n",
      "Reading chunk:  95 of 358 ( 26.54 %)\n",
      "Reading chunk:  96 of 358 ( 26.82 %)\n",
      "Reading chunk:  97 of 358 ( 27.09 %)\n",
      "Reading chunk:  98 of 358 ( 27.37 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  99 of 358 ( 27.65 %)\n",
      "Reading chunk:  100 of 358 ( 27.93 %)\n",
      "Reading chunk:  101 of 358 ( 28.21 %)\n",
      "Reading chunk:  102 of 358 ( 28.49 %)\n",
      "Reading chunk:  103 of 358 ( 28.77 %)\n",
      "Reading chunk:  104 of 358 ( 29.05 %)\n",
      "Reading chunk:  105 of 358 ( 29.33 %)\n",
      "Reading chunk:  106 of 358 ( 29.61 %)\n",
      "Reading chunk:  107 of 358 ( 29.89 %)\n",
      "Reading chunk:  108 of 358 ( 30.17 %)\n",
      "Reading chunk:  109 of 358 ( 30.45 %)\n",
      "Reading chunk:  110 of 358 ( 30.73 %)\n",
      "Reading chunk:  111 of 358 ( 31.01 %)\n",
      "Reading chunk:  112 of 358 ( 31.28 %)\n",
      "Reading chunk:  113 of 358 ( 31.56 %)\n",
      "Reading chunk:  114 of 358 ( 31.84 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  115 of 358 ( 32.12 %)\n",
      "Reading chunk:  116 of 358 ( 32.4 %)\n",
      "Reading chunk:  117 of 358 ( 32.68 %)\n",
      "Reading chunk:  118 of 358 ( 32.96 %)\n",
      "Reading chunk:  119 of 358 ( 33.24 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  120 of 358 ( 33.52 %)\n",
      "Reading chunk:  121 of 358 ( 33.8 %)\n",
      "Reading chunk:  122 of 358 ( 34.08 %)\n",
      "Reading chunk:  123 of 358 ( 34.36 %)\n",
      "Reading chunk:  124 of 358 ( 34.64 %)\n",
      "Reading chunk:  125 of 358 ( 34.92 %)\n",
      "Reading chunk:  126 of 358 ( 35.2 %)\n",
      "Reading chunk:  127 of 358 ( 35.47 %)\n",
      "Reading chunk:  128 of 358 ( 35.75 %)\n",
      "Reading chunk:  129 of 358 ( 36.03 %)\n",
      "Reading chunk:  130 of 358 ( 36.31 %)\n",
      "Reading chunk:  131 of 358 ( 36.59 %)\n",
      "Reading chunk:  132 of 358 ( 36.87 %)\n",
      "Reading chunk:  133 of 358 ( 37.15 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  134 of 358 ( 37.43 %)\n",
      "Reading chunk:  135 of 358 ( 37.71 %)\n",
      "Reading chunk:  136 of 358 ( 37.99 %)\n",
      "Reading chunk:  137 of 358 ( 38.27 %)\n",
      "Reading chunk:  138 of 358 ( 38.55 %)\n",
      "Reading chunk:  139 of 358 ( 38.83 %)\n",
      "Reading chunk:  140 of 358 ( 39.11 %)\n",
      "Reading chunk:  141 of 358 ( 39.39 %)\n",
      "Reading chunk:  142 of 358 ( 39.66 %)\n",
      "Reading chunk:  143 of 358 ( 39.94 %)\n",
      "Reading chunk:  144 of 358 ( 40.22 %)\n",
      "Reading chunk:  145 of 358 ( 40.5 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  146 of 358 ( 40.78 %)\n",
      "Reading chunk:  147 of 358 ( 41.06 %)\n",
      "Reading chunk:  148 of 358 ( 41.34 %)\n",
      "Reading chunk:  149 of 358 ( 41.62 %)\n",
      "Reading chunk:  150 of 358 ( 41.9 %)\n",
      "Reading chunk:  151 of 358 ( 42.18 %)\n",
      "Reading chunk:  152 of 358 ( 42.46 %)\n",
      "Reading chunk:  153 of 358 ( 42.74 %)\n",
      "Reading chunk:  154 of 358 ( 43.02 %)\n",
      "Reading chunk:  155 of 358 ( 43.3 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  156 of 358 ( 43.58 %)\n",
      "Reading chunk:  157 of 358 ( 43.85 %)\n",
      "Reading chunk:  158 of 358 ( 44.13 %)\n",
      "Reading chunk:  159 of 358 ( 44.41 %)\n",
      "Reading chunk:  160 of 358 ( 44.69 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  161 of 358 ( 44.97 %)\n",
      "Reading chunk:  162 of 358 ( 45.25 %)\n",
      "Reading chunk:  163 of 358 ( 45.53 %)\n",
      "Reading chunk:  164 of 358 ( 45.81 %)\n",
      "Reading chunk:  165 of 358 ( 46.09 %)\n",
      "Reading chunk:  166 of 358 ( 46.37 %)\n",
      "Reading chunk:  167 of 358 ( 46.65 %)\n",
      "Reading chunk:  168 of 358 ( 46.93 %)\n",
      "Reading chunk:  169 of 358 ( 47.21 %)\n",
      "Reading chunk:  170 of 358 ( 47.49 %)\n",
      "Reading chunk:  171 of 358 ( 47.77 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  172 of 358 ( 48.04 %)\n",
      "Reading chunk:  173 of 358 ( 48.32 %)\n",
      "Reading chunk:  174 of 358 ( 48.6 %)\n",
      "Reading chunk:  175 of 358 ( 48.88 %)\n",
      "Reading chunk:  176 of 358 ( 49.16 %)\n",
      "Reading chunk:  177 of 358 ( 49.44 %)\n",
      "Reading chunk:  178 of 358 ( 49.72 %)\n",
      "Reading chunk:  179 of 358 ( 50.0 %)\n",
      "Reading chunk:  180 of 358 ( 50.28 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  181 of 358 ( 50.56 %)\n",
      "Reading chunk:  182 of 358 ( 50.84 %)\n",
      "Reading chunk:  183 of 358 ( 51.12 %)\n",
      "Reading chunk:  184 of 358 ( 51.4 %)\n",
      "Reading chunk:  185 of 358 ( 51.68 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  186 of 358 ( 51.96 %)\n",
      "Reading chunk:  187 of 358 ( 52.23 %)\n",
      "Reading chunk:  188 of 358 ( 52.51 %)\n",
      "Reading chunk:  189 of 358 ( 52.79 %)\n",
      "Reading chunk:  190 of 358 ( 53.07 %)\n",
      "Reading chunk:  191 of 358 ( 53.35 %)\n",
      "Reading chunk:  192 of 358 ( 53.63 %)\n",
      "Reading chunk:  193 of 358 ( 53.91 %)\n",
      "Reading chunk:  194 of 358 ( 54.19 %)\n",
      "Reading chunk:  195 of 358 ( 54.47 %)\n",
      "Reading chunk:  196 of 358 ( 54.75 %)\n",
      "Reading chunk:  197 of 358 ( 55.03 %)\n",
      "Reading chunk:  198 of 358 ( 55.31 %)\n",
      "Reading chunk:  199 of 358 ( 55.59 %)\n",
      "Reading chunk:  200 of 358 ( 55.87 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  201 of 358 ( 56.15 %)\n",
      "Reading chunk:  202 of 358 ( 56.42 %)\n",
      "Reading chunk:  203 of 358 ( 56.7 %)\n",
      "Reading chunk:  204 of 358 ( 56.98 %)\n",
      "Reading chunk:  205 of 358 ( 57.26 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  206 of 358 ( 57.54 %)\n",
      "Reading chunk:  207 of 358 ( 57.82 %)\n",
      "Reading chunk:  208 of 358 ( 58.1 %)\n",
      "Reading chunk:  209 of 358 ( 58.38 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  210 of 358 ( 58.66 %)\n",
      "Reading chunk:  211 of 358 ( 58.94 %)\n",
      "Reading chunk:  212 of 358 ( 59.22 %)\n",
      "Reading chunk:  213 of 358 ( 59.5 %)\n",
      "Reading chunk:  214 of 358 ( 59.78 %)\n",
      "Reading chunk:  215 of 358 ( 60.06 %)\n",
      "Reading chunk:  216 of 358 ( 60.34 %)\n",
      "Reading chunk:  217 of 358 ( 60.61 %)\n",
      "Reading chunk:  218 of 358 ( 60.89 %)\n",
      "Reading chunk:  219 of 358 ( 61.17 %)\n",
      "Reading chunk:  220 of 358 ( 61.45 %)\n",
      "Reading chunk:  221 of 358 ( 61.73 %)\n",
      "Reading chunk:  222 of 358 ( 62.01 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  223 of 358 ( 62.29 %)\n",
      "Reading chunk:  224 of 358 ( 62.57 %)\n",
      "Reading chunk:  225 of 358 ( 62.85 %)\n",
      "Reading chunk:  226 of 358 ( 63.13 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  227 of 358 ( 63.41 %)\n",
      "Reading chunk:  228 of 358 ( 63.69 %)\n",
      "Reading chunk:  229 of 358 ( 63.97 %)\n",
      "Reading chunk:  230 of 358 ( 64.25 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  231 of 358 ( 64.53 %)\n",
      "Reading chunk:  232 of 358 ( 64.8 %)\n",
      "Reading chunk:  233 of 358 ( 65.08 %)\n",
      "Reading chunk:  234 of 358 ( 65.36 %)\n",
      "Reading chunk:  235 of 358 ( 65.64 %)\n",
      "Reading chunk:  236 of 358 ( 65.92 %)\n",
      "Reading chunk:  237 of 358 ( 66.2 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  238 of 358 ( 66.48 %)\n",
      "Reading chunk:  239 of 358 ( 66.76 %)\n",
      "Reading chunk:  240 of 358 ( 67.04 %)\n",
      "Reading chunk:  241 of 358 ( 67.32 %)\n",
      "Reading chunk:  242 of 358 ( 67.6 %)\n",
      "Reading chunk:  243 of 358 ( 67.88 %)\n",
      "Reading chunk:  244 of 358 ( 68.16 %)\n",
      "Reading chunk:  245 of 358 ( 68.44 %)\n",
      "Reading chunk:  246 of 358 ( 68.72 %)\n",
      "Reading chunk:  247 of 358 ( 68.99 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  248 of 358 ( 69.27 %)\n",
      "Reading chunk:  249 of 358 ( 69.55 %)\n",
      "Reading chunk:  250 of 358 ( 69.83 %)\n",
      "Reading chunk:  251 of 358 ( 70.11 %)\n",
      "Reading chunk:  252 of 358 ( 70.39 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  253 of 358 ( 70.67 %)\n",
      "Reading chunk:  254 of 358 ( 70.95 %)\n",
      "Reading chunk:  255 of 358 ( 71.23 %)\n",
      "Reading chunk:  256 of 358 ( 71.51 %)\n",
      "Reading chunk:  257 of 358 ( 71.79 %)\n",
      "Reading chunk:  258 of 358 ( 72.07 %)\n",
      "Reading chunk:  259 of 358 ( 72.35 %)\n",
      "Reading chunk:  260 of 358 ( 72.63 %)\n",
      "Reading chunk:  261 of 358 ( 72.91 %)\n",
      "Reading chunk:  262 of 358 ( 73.18 %)\n",
      "Reading chunk:  263 of 358 ( 73.46 %)\n",
      "Reading chunk:  264 of 358 ( 73.74 %)\n",
      "Reading chunk:  265 of 358 ( 74.02 %)\n",
      "Reading chunk:  266 of 358 ( 74.3 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  267 of 358 ( 74.58 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  268 of 358 ( 74.86 %)\n",
      "Reading chunk:  269 of 358 ( 75.14 %)\n",
      "Reading chunk:  270 of 358 ( 75.42 %)\n",
      "Reading chunk:  271 of 358 ( 75.7 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  272 of 358 ( 75.98 %)\n",
      "Reading chunk:  273 of 358 ( 76.26 %)\n",
      "Reading chunk:  274 of 358 ( 76.54 %)\n",
      "Reading chunk:  275 of 358 ( 76.82 %)\n",
      "Reading chunk:  276 of 358 ( 77.09 %)\n",
      "Reading chunk:  277 of 358 ( 77.37 %)\n",
      "Reading chunk:  278 of 358 ( 77.65 %)\n",
      "Reading chunk:  279 of 358 ( 77.93 %)\n",
      "Reading chunk:  280 of 358 ( 78.21 %)\n",
      "Reading chunk:  281 of 358 ( 78.49 %)\n",
      "Reading chunk:  282 of 358 ( 78.77 %)\n",
      "Reading chunk:  283 of 358 ( 79.05 %)\n",
      "Reading chunk:  284 of 358 ( 79.33 %)\n",
      "Reading chunk:  285 of 358 ( 79.61 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  286 of 358 ( 79.89 %)\n",
      "Reading chunk:  287 of 358 ( 80.17 %)\n",
      "Reading chunk:  288 of 358 ( 80.45 %)\n",
      "Reading chunk:  289 of 358 ( 80.73 %)\n",
      "Reading chunk:  290 of 358 ( 81.01 %)\n",
      "Reading chunk:  291 of 358 ( 81.28 %)\n",
      "Reading chunk:  292 of 358 ( 81.56 %)\n",
      "Reading chunk:  293 of 358 ( 81.84 %)\n",
      "Reading chunk:  294 of 358 ( 82.12 %)\n",
      "Reading chunk:  295 of 358 ( 82.4 %)\n",
      "Reading chunk:  296 of 358 ( 82.68 %)\n",
      "Reading chunk:  297 of 358 ( 82.96 %)\n",
      "Reading chunk:  298 of 358 ( 83.24 %)\n",
      "Reading chunk:  299 of 358 ( 83.52 %)\n",
      "Reading chunk:  300 of 358 ( 83.8 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  301 of 358 ( 84.08 %)\n",
      "Reading chunk:  302 of 358 ( 84.36 %)\n",
      "Reading chunk:  303 of 358 ( 84.64 %)\n",
      "Reading chunk:  304 of 358 ( 84.92 %)\n",
      "Reading chunk:  305 of 358 ( 85.2 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  306 of 358 ( 85.47 %)\n",
      "Reading chunk:  307 of 358 ( 85.75 %)\n",
      "Reading chunk:  308 of 358 ( 86.03 %)\n",
      "Reading chunk:  309 of 358 ( 86.31 %)\n",
      "Reading chunk:  310 of 358 ( 86.59 %)\n",
      "Reading chunk:  311 of 358 ( 86.87 %)\n",
      "Reading chunk:  312 of 358 ( 87.15 %)\n",
      "Reading chunk:  313 of 358 ( 87.43 %)\n",
      "Reading chunk:  314 of 358 ( 87.71 %)\n",
      "Reading chunk:  315 of 358 ( 87.99 %)\n",
      "Reading chunk:  316 of 358 ( 88.27 %)\n",
      "Reading chunk:  317 of 358 ( 88.55 %)\n",
      "Reading chunk:  318 of 358 ( 88.83 %)\n",
      "Reading chunk:  319 of 358 ( 89.11 %)\n",
      "Reading chunk:  320 of 358 ( 89.39 %)\n",
      "Reading chunk:  321 of 358 ( 89.66 %)\n",
      "Reading chunk:  322 of 358 ( 89.94 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  323 of 358 ( 90.22 %)\n",
      "Reading chunk:  324 of 358 ( 90.5 %)\n",
      "Reading chunk:  325 of 358 ( 90.78 %)\n",
      "Reading chunk:  326 of 358 ( 91.06 %)\n",
      "Reading chunk:  327 of 358 ( 91.34 %)\n",
      "Reading chunk:  328 of 358 ( 91.62 %)\n",
      "Reading chunk:  329 of 358 ( 91.9 %)\n",
      "Reading chunk:  330 of 358 ( 92.18 %)\n",
      "Reading chunk:  331 of 358 ( 92.46 %)\n",
      "Reading chunk:  332 of 358 ( 92.74 %)\n",
      "Reading chunk:  333 of 358 ( 93.02 %)\n",
      "Reading chunk:  334 of 358 ( 93.3 %)\n",
      "Reading chunk:  335 of 358 ( 93.58 %)\n",
      "Reading chunk:  336 of 358 ( 93.85 %)\n",
      "Reading chunk:  337 of 358 ( 94.13 %)\n",
      "Reading chunk:  338 of 358 ( 94.41 %)\n",
      "Reading chunk:  339 of 358 ( 94.69 %)\n",
      "Reading chunk:  340 of 358 ( 94.97 %)\n",
      "Reading chunk:  341 of 358 ( 95.25 %)\n",
      "Reading chunk:  342 of 358 ( 95.53 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  343 of 358 ( 95.81 %)\n",
      "Reading chunk:  344 of 358 ( 96.09 %)\n",
      "Reading chunk:  345 of 358 ( 96.37 %)\n",
      "Reading chunk:  346 of 358 ( 96.65 %)\n",
      "Reading chunk:  347 of 358 ( 96.93 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  348 of 358 ( 97.21 %)\n",
      "Reading chunk:  349 of 358 ( 97.49 %)\n",
      "Reading chunk:  350 of 358 ( 97.77 %)\n",
      "Reading chunk:  351 of 358 ( 98.04 %)\n",
      "Reading chunk:  352 of 358 ( 98.32 %)\n",
      "Reading chunk:  353 of 358 ( 98.6 %)\n",
      "Reading chunk:  354 of 358 ( 98.88 %)\n",
      "Reading chunk:  355 of 358 ( 99.16 %)\n",
      "Reading chunk:  356 of 358 ( 99.44 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/hh7cth4s3p3dbtdpc8j1m9bm0000gn/T/ipykernel_84200/1094468042.py:9: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chunk:  357 of 358 ( 99.72 %)\n",
      "Reading chunk:  358 of 358 ( 100.0 %)\n",
      "Ingest complete\n"
     ]
    }
   ],
   "source": [
    "# Ingest the WAPO file as chunks\n",
    "\n",
    "chunks = 500000  # Leave this, there will be 358 chunks\n",
    "\n",
    "chunk_counter = 0\n",
    "\n",
    "wapo_df = pd.DataFrame()\n",
    "\n",
    "for chunk in pd.read_csv(\n",
    "    wapo,\n",
    "    sep=\"\\t\",\n",
    "    compression=\"gzip\",\n",
    "    chunksize=chunks,\n",
    "    usecols=[\n",
    "        \"BUYER_COUNTY\",\n",
    "        \"BUYER_STATE\",\n",
    "        \"DRUG_NAME\",\n",
    "        \"TRANSACTION_DATE\",\n",
    "        \"QUANTITY\",\n",
    "        \"UNIT\",\n",
    "    ],\n",
    "):\n",
    "    chunk_counter += 1\n",
    "    percent_chunk = round(chunk_counter / 358 * 100, 2)\n",
    "    print(\"Reading chunk: \", chunk_counter, \"of 358 (\", percent_chunk, \"%)\")\n",
    "\n",
    "    # filter the chunk to only include the stations in the list\n",
    "    chunk = chunk[chunk[\"BUYER_STATE\"].isin(states)].copy()\n",
    "\n",
    "    chunk[\"TRANSACTION_DATE\"] = pd.to_datetime(\n",
    "        chunk[\"TRANSACTION_DATE\"], format=\"%m%d%Y\"\n",
    "    )\n",
    "\n",
    "    chunk[\"YEAR\"] = chunk[\"TRANSACTION_DATE\"].dt.year\n",
    "    chunk[\"MONTH\"] = chunk[\"TRANSACTION_DATE\"].dt.month\n",
    "\n",
    "    chunk = chunk.groupby([\"BUYER_COUNTY\", \"BUYER_STATE\", \"YEAR\", \"MONTH\"]).agg(\n",
    "        {\"QUANTITY\": \"sum\"}\n",
    "    )\n",
    "\n",
    "    # concat with the base df\n",
    "    wapo_df = pd.concat([wapo_df, chunk])\n",
    "\n",
    "print(\"Ingest complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding county name...\n",
      "Grouping WAPO data...\n",
      "Operation complete\n"
     ]
    }
   ],
   "source": [
    "# transform the wapo df\n",
    "print(\"Adding county name...\")\n",
    "\n",
    "# Add an index to the wapo_df\n",
    "wapo_df = wapo_df.reset_index()\n",
    "\n",
    "# Do some transformations on the WAPO dataset\n",
    "wapo_df[\"COUNTY_NAME\"] = wapo_df[\"BUYER_COUNTY\"] + \" COUNTY, \" + wapo_df[\"BUYER_STATE\"]\n",
    "\n",
    "print(\"Grouping WAPO data...\")\n",
    "\n",
    "wapo_df = (\n",
    "    wapo_df.groupby([\"COUNTY_NAME\", \"BUYER_STATE\", \"YEAR\", \"MONTH\"])\n",
    "    .agg({\"QUANTITY\": \"sum\"})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# rename buyer state to state\n",
    "wapo_df = wapo_df.rename(columns={\"BUYER_STATE\": \"STATE\"})\n",
    "\n",
    "print(\"Operation complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Print a sample to make sure you did it right***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(wapo_df.sample(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Assert tests to verify that we have the right states, and some checks on the data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert that no counties are missing\n",
    "assert wapo_df[\"COUNTY_NAME\"].isnull().sum() == 0\n",
    "# Assert that states are in the list\n",
    "assert set(wapo_df[\"STATE\"].unique()) == set(states)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Save the output file to a csv in the intermediate files directory***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this file as a csv called wapo_clean.csv in the current directory\n",
    "wapo_df.to_csv(\"../20_intermediate_files/wapo_clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vitality Data\n",
    "\n",
    "This section takes the txt files passed and will return a dataframe with the respective values for each year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ingest actions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a directory path to find the txt files\n",
    "nick_path = \"../00_source_data/US_VitalStatistics/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting text files...\n",
      "Transforming vitality data...\n",
      "Operation complete\n"
     ]
    }
   ],
   "source": [
    "# generate a df from the txt files in a folder path\n",
    "\n",
    "# initialize the empty df\n",
    "nick_df = pd.DataFrame()\n",
    "\n",
    "# set a loop to iterate through the files in the folder\n",
    "print(\"Ingesting text files...\")\n",
    "\n",
    "# set a loop to iterate through the files in the folder\n",
    "for file in os.listdir(nick_path):\n",
    "    if file.endswith(\".txt\"):\n",
    "        txt_table = pd.read_table(\n",
    "            os.path.join(nick_path, file), sep=\"\\t\", skipfooter=15, engine=\"python\"\n",
    "        )\n",
    "        # remove the bottom rows that are not needed\n",
    "        txt_table = txt_table.iloc[0:-16, :]\n",
    "        nick_df = pd.concat([nick_df, txt_table], axis=0)\n",
    "\n",
    "# subset to the columns we want\n",
    "vital_df = nick_df[\n",
    "    [\n",
    "        \"County\",\n",
    "        \"County Code\",\n",
    "        \"Year\",\n",
    "        \"Drug/Alcohol Induced Cause\",\n",
    "        \"Drug/Alcohol Induced Cause Code\",\n",
    "        \"Deaths\",\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "print(\"Transforming vitality data...\")\n",
    "\n",
    "# change the year column to a date time object with a year only\n",
    "vital_df[\"Year\"] = pd.to_datetime(vital_df[\"Year\"], format=\"%Y\")\n",
    "\n",
    "# change the County Code column to 6-digit string FIPS code\n",
    "vital_df[\"County Code\"] = vital_df[\"County Code\"].astype(str).str.zfill(6)\n",
    "\n",
    "# add a state column with the last two characters from county\n",
    "vital_df[\"State\"] = vital_df[\"County\"].str[-2:]\n",
    "\n",
    "# convert NaN deaths to 0\n",
    "vital_df[\"Deaths\"] = vital_df[\"Deaths\"].fillna(0)\n",
    "\n",
    "# change the county name to all caps\n",
    "vital_df[\"County\"] = vital_df[\"County\"].str.upper()\n",
    "\n",
    "# change all the column names to all caps\n",
    "vital_df.columns = vital_df.columns.str.upper()\n",
    "\n",
    "# rename county code to FIPS code\n",
    "vital_df = vital_df.rename(columns={\"COUNTY CODE\": \"FIPS\"})\n",
    "\n",
    "# filter the vital df to the states of interest\n",
    "vital_df = vital_df[vital_df[\"STATE\"].isin(states)].copy()\n",
    "\n",
    "print(\"Operation complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Check a sample to inspect data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vital_df.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Assert tests to verify that we have the right states, and some checks on the data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert vital_df.all().isnull().sum() == 0\n",
    "# Assert that states are in the list\n",
    "assert set(vital_df[\"STATE\"].unique()) == set(states)\n",
    "# Still need to find a way to check if Vital is correctly chunked\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Save the output dataframe to the intermediate files directory***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vital_df.to_csv(\"../20_intermediate_files/vital_clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add FIPS Codes to the available data\n",
    "\n",
    "This chunk takes the path to FIPS codes and will ingest them into a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ingest data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_path = \"../00_source_data/02_fcc_fips_codes.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***start with counties***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation complete\n"
     ]
    }
   ],
   "source": [
    "# Ingest the fips codes\n",
    "fips_county_df = pd.read_table(fips_path, sep=\"\\t\", skiprows=71, header=\"infer\")\n",
    "\n",
    "# name the column header\n",
    "fips_county_df.columns = [\"FIPS\"]\n",
    "\n",
    "# split the FIPS column into two columns after the first 5 characters\n",
    "fips_county_df[\"COUNTY_NAME\"] = fips_county_df[\"FIPS\"].str[10:]\n",
    "\n",
    "# Turn the FIPS column into just the numbers\n",
    "fips_county_df[\"FIPS\"] = fips_county_df[\"FIPS\"].str[4:10]\n",
    "\n",
    "# remove the spaces from the county name\n",
    "fips_county_df[\"COUNTY_NAME\"] = fips_county_df[\"COUNTY_NAME\"].str.strip()\n",
    "\n",
    "# make county name upper\n",
    "fips_county_df[\"COUNTY_NAME\"] = fips_county_df[\"COUNTY_NAME\"].str.upper()\n",
    "\n",
    "print(\"Operation complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation complete\n"
     ]
    }
   ],
   "source": [
    "# Ingest the fips codes\n",
    "fips_state_df = pd.read_table(fips_path, sep=\"\\t\", skiprows=15, header=\"infer\")\n",
    "\n",
    "# keep the first 50 rows\n",
    "fips_state_df = fips_state_df.iloc[0:50, :]\n",
    "\n",
    "# name the column header\n",
    "fips_state_df.columns = [\"FIPS\"]\n",
    "\n",
    "# # split the FIPS column into two columns after the first 5 characters\n",
    "fips_state_df[\"STATE\"] = fips_state_df[\"FIPS\"].str[10:]\n",
    "fips_state_df[\"STATE\"] = fips_state_df[\"STATE\"].str.strip()\n",
    "\n",
    "# #Turn the FIPS column into just the numbers\n",
    "fips_state_df[\"FIPS\"] = fips_state_df[\"FIPS\"].str[4:10]\n",
    "\n",
    "# merge to add the state abbreviations from the state_df\n",
    "fips_state_df = fips_state_df.merge(state_df, on=\"STATE\", how=\"left\")\n",
    "\n",
    "print(\"Operation complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***merge the two dataframes***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is going to be a little different\n",
    "fips_df = fips_county_df.copy()\n",
    "\n",
    "# add a state column\n",
    "fips_df[\"STATE\"] = fips_df[\"COUNTY_NAME\"]\n",
    "\n",
    "# merge to get the state abbreviations\n",
    "fips_df = fips_df.merge(fips_state_df, on=\"STATE\", how=\"left\")\n",
    "\n",
    "# drop the state column\n",
    "fips_df = fips_df.drop(columns=[\"STATE\"])\n",
    "\n",
    "# rename the columns\n",
    "fips_df = fips_df.rename(\n",
    "    columns={\"FIPS_x\": \"FIPS\", \"ABBREV\": \"STATE\", \"FIPS_y\": \"STATE_FIPS\"}\n",
    ")\n",
    "\n",
    "# forward fill the state fips and state columns\n",
    "fips_df[\"STATE_FIPS\"] = fips_df[\"STATE_FIPS\"].fillna(method=\"ffill\")\n",
    "fips_df[\"STATE\"] = fips_df[\"STATE\"].fillna(method=\"ffill\")\n",
    "\n",
    "# add state to the county name\n",
    "fips_df[\"COUNTY_NAME\"] = fips_df[\"COUNTY_NAME\"] + \", \" + fips_df[\"STATE\"]\n",
    "\n",
    "# filter the df to the states of interest\n",
    "fips_df = fips_df[fips_df[\"STATE\"].isin(states)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Sample the FIPS codes to see if we did it right***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fips_df.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Add some assert tests***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert vital_df.all().isnull().sum() == 0\n",
    "# check the first two digits of the FIPS code to make sure they match with STATE_FIPS\n",
    "assert list(fips_df[\"FIPS\"].str[:2]) == list(\n",
    "    fips_df[\"STATE_FIPS\"].astype(str).str.strip()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Save the FIPS file cleaned to the 20_intermediate_files directory***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fips_df to a csv\n",
    "fips_df.to_csv(\"../20_intermediate_files/fips_df.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census Data\n",
    "\n",
    "This chunk will ingest filtered county population data and return a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ingest data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the directory path to the raw data\n",
    "census_path = \"../00_source_data/01_census_data.xlsx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingest the raw data and filter for states of interest\n",
    "census_df = pd.read_excel(census_path, header=0, skiprows=4, usecols=\"A:B\")\n",
    "\n",
    "# Change the column names to county name and population\n",
    "census_df.columns = [\"COUNTY_NAME\", \"POPULATION\"]\n",
    "\n",
    "# remove the leading period from the county name\n",
    "census_df[\"COUNTY_NAME\"] = census_df[\"COUNTY_NAME\"].str[1:]\n",
    "\n",
    "# move the state name to its own column\n",
    "census_df[\"STATE\"] = census_df[\"COUNTY_NAME\"].str.split(\",\").str[1]\n",
    "census_df[\"STATE\"] = census_df[\"STATE\"].str.strip()\n",
    "census_df[\"STATE\"] = census_df[\"STATE\"].str.upper()\n",
    "\n",
    "# remove the state name from the county name\n",
    "census_df[\"COUNTY_NAME\"] = census_df[\"COUNTY_NAME\"].str.split(\",\").str[0]\n",
    "\n",
    "# change population to an integer\n",
    "census_df[\"POPULATION\"] = census_df[\"POPULATION\"].astype(\"Int64\")\n",
    "\n",
    "# add an abbreviation column for the state from the state_df\n",
    "census_df_merge = census_df.merge(state_df, on=\"STATE\", how=\"outer\")\n",
    "\n",
    "# reformat county name to include abbrev\n",
    "census_df_merge[\"COUNTY_NAME\"] = (\n",
    "    census_df_merge[\"COUNTY_NAME\"] + \", \" + census_df_merge[\"ABBREV\"]\n",
    ")\n",
    "census_df_merge[\"COUNTY_NAME\"] = census_df_merge[\"COUNTY_NAME\"].str.upper()\n",
    "\n",
    "# remove the state column\n",
    "census_df_merge = census_df_merge.drop(columns=\"STATE\")\n",
    "\n",
    "# rename the abbrev column to state\n",
    "census_df_merge = census_df_merge.rename(columns={\"ABBREV\": \"STATE\"})\n",
    "\n",
    "# filter for the states of interest\n",
    "census_df_merge = census_df_merge[census_df_merge[\"STATE\"].isin(states)].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Sample to see if we did it right***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# census_df_merge.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Add assert tests***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert census_df_merge.all().isnull().sum() == 0\n",
    "# check last two characters of county name to make sure they match with state\n",
    "assert list(census_df_merge[\"COUNTY_NAME\"].str[-2:]) == list(census_df_merge[\"STATE\"])\n",
    "# we need to check county numbers to make sure they match (when we know which control states we want)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Save the output file to the intermediate files directory***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the file to the intermediate folder\n",
    "census_df_merge.to_csv(\"../20_intermediate_files/census_df.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8252741f7dece6ad0987207e3211c729db738b68c7c87111815d7232d469f1e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
